{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Analysis\n",
    "_**HARD: This is a curveball assignment. Plus, this is Python without Pandas.**_\n",
    "\n",
    "#### The objective of this assignment is for you to explain what is happening in each cell in clear, understandable language. \n",
    "\n",
    "#### _There is no need to code._ The code is there for you, and it already runs. Your task is only to explain what each line in each cell does.\n",
    "\n",
    "#### The placeholder cells should describe what happens in the cell below it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below imports `os` as a dependency because the `os.path.join` function. Also, the `string` dependency is needed because later in the script, `string.punctuation` will be used to detect and remove punctuation symbols. Explain what the line `from collection import Counter` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, you are creating a path to the csv in order to manipulate the data throughout the code. \n",
    "\n",
    "The REQUIRED_SKILLS and DESIRED_SKILLS are both being set as new varibles that inlcude the \"specific\" values from the text. The variable names are in all caps because they are being set as constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "resume_path = os.path.join(\".\", 'resume.md')\n",
    "\n",
    "# Skills to match\n",
    "REQUIRED_SKILLS = {\"excel\", \"python\", \"mysql\", \"statistics\"}\n",
    "DESIRED_SKILLS = {\"r\", \"git\", \"html\", \"css\", \"leaflet\", \"modeling\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, the load_file function is being defined to set up how a file will load in to python. The subsequent steps will be followed anytime a new file is read. You then use a helper function in order to open read the file, open(filepath, \"r\") as resumer_file_handler. *\"r\" denotes that you are reading* \n",
    "\n",
    "You then run the file through several functions in order to make it as easy to manipulate as possible:\n",
    ".read() reads the file in to a new variable, resume_contents\n",
    ".lower() makes all letters in the variable lowercase \n",
    ".split() defines a new variable (resume_tokens), and splits the values in resume_contents by a seperator (which defaults to \",\" if it is not otherwise defined)\n",
    "Return function will then return the read, lowercase, and split data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_file(filepath):\n",
    "    # Helper function to read a file and return the data.\n",
    "    with open(filepath, \"r\") as resume_file_handler:\n",
    "        resume_contents = resume_file_handler.read()\n",
    "        resume_contents = resume_contents.lower()\n",
    "        resume_tokens = resume_contents.split()\n",
    "        return resume_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is going to utilize the load_file function defined above to read in the resume_path we defined in the first line of code, pulling in data from the text file. \n",
    "\n",
    "word_list will become the new variable reference for that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the text for a Resume\n",
    "word_list = load_file(resume_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set() is created in order to have a blank list for items returned in the loop to be added to.\n",
    "\n",
    "We populate the set by looping through the individual values in word_list and using .add to add them to the resume set we created\n",
    "\n",
    "set(string.punctuation) is a fucntion that will parse the data set specifically for punctuation and add it to the new variable set, puncutation. It is necessary to create a punctuation set because the data was looped through and returned all tokens or pieces of information included in the data, the punctuation could return inaccuarate information as we continue to evaluate if it is not removed. \n",
    "\n",
    "In order to return only the words in the resume set, the values identified as punctutaiton need to be subtracted. We do this by subtracting our puntuation set from the resume set, which removes all matching values.  \n",
    "\n",
    "'\\n' is a function that denotes that the information returned from a function should be printed on a new line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WORDS BEFORE MOVING PUNCTUATION\n",
      "{'machine', 'hadoop,', 'python,', 'apis.', 'web', 'pivot', 'front-end', 'modeling', 'and', 'apps', 'leaflet.js', 'designing', 'basic', 'stein', 'git/github', 'big', 'hadoop', 'aws', 'n.', 'skills', '*', 'd3,', 'experience', 'statistics', 'excel,', 'interests', '#', 'to', 'forecasting', 'mining,', 'the', 'software', 'graduate', 'excel.', 'performing', 'visualizations', 'r,', 'media', 'learning', 'education', 'microsoft', 'creating', 'bootstrap,', 'writing', 'from', '##', 'camp', 'open-source', 'files', 'scripts', 'd3', 'data', 'analyze', 'intelligence', 'social', 'tables', 'working', 'analytics', 'cloud', 'mining', 'advanced', 'business', 'tableau,', 'learning,', 'pandas', 'vba', 'using', 'tableau', 'frank', 'developing', 'api', 'contributing', 'interactions,', 'sql,', 'in', 'boot', 'python', 'mongodb', 'sets', 'with', 'statistics,', 'javascript,', 'mysql', 'css,', 'algorithms', 'html,', 'visualization', 'html/css,', 'databases'}\n",
      "\n",
      "WORDS AFTER MOVING PUNCTUATION\n",
      "{'machine', 'hadoop,', 'python,', 'apis.', 'web', 'pivot', 'front-end', 'modeling', 'and', 'apps', 'leaflet.js', 'designing', 'basic', 'stein', 'git/github', 'big', 'hadoop', 'aws', 'n.', 'skills', 'experience', 'd3,', 'statistics', 'excel,', 'interests', 'to', 'forecasting', 'mining,', 'the', 'software', 'graduate', 'excel.', 'performing', 'visualizations', 'r,', 'media', 'learning', 'education', 'microsoft', 'creating', 'bootstrap,', 'writing', 'from', '##', 'camp', 'open-source', 'files', 'scripts', 'd3', 'data', 'analyze', 'intelligence', 'social', 'tables', 'working', 'analytics', 'cloud', 'mining', 'advanced', 'business', 'tableau,', 'learning,', 'pandas', 'vba', 'using', 'tableau', 'frank', 'developing', 'api', 'contributing', 'interactions,', 'sql,', 'in', 'boot', 'python', 'mongodb', 'sets', 'with', 'statistics,', 'javascript,', 'mysql', 'css,', 'algorithms', 'html,', 'visualization', 'html/css,', 'databases'}\n"
     ]
    }
   ],
   "source": [
    "# Create a set of unique words from the resume\n",
    "resume = set()\n",
    "\n",
    "# HINT: Single elements in a programming language are often referred to as tokens\n",
    "for token in word_list:\n",
    "    resume.add(token)\n",
    "\n",
    "print('\\nWORDS BEFORE MOVING PUNCTUATION')    \n",
    "print(resume)\n",
    "\n",
    "# Remove Punctuation that were read as whole words\n",
    "punctuation = set(string.punctuation)\n",
    "# HINT: Attributes that are in `resume` that are not in `punctuation` (difference)\n",
    "resume = (resume - punctuation)\n",
    "\n",
    "print('\\nWORDS AFTER MOVING PUNCTUATION')    \n",
    "print(resume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, the set intersection is being used to return the words that are in both the constants we defined before and the  resume file we are reading to see where they overlap. \n",
    "\n",
    "The key difference between the word and character cleaning functions is what you are parsing through in the data set. In this case words v. characters. \n",
    "\n",
    "The word cleaning function is looking for words in the word list that are not in string.punctuation, returning the elements sans attached puncutation. \n",
    "\n",
    "The character cleaning function is written to parse the values for any characters, and remove them and the \" \" attached to them (denoted by the \" \".join function). This returns only the values in the list that are actually words. \n",
    "\n",
    "For the stop words list and cleaning function, you are able to manipulate the values in the stop_words list and it will update the values that the cleaning function returns. \n",
    "\n",
    "In each of the functions below, word_list is operating as the varible to call the data from the resume file we are reading. The list comprehensions are allowing us to parse through this list and return the values that meet the condition set. For example, stop words says, for all return word in the word_list, if that word is not also found in stop_words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REQUIRED SKILLS\n",
      "{'mysql', 'statistics', 'python'}\n",
      "DESIRED SKILLS\n",
      "{'modeling'}\n",
      "\n",
      "WORD LIST AFTER PUNCTUATION REMOVAL\n",
      "['n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n",
      "\n",
      "WORD LIST AFTER CHARACTER PUNCTUATION REMOVAL\n",
      "['n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n",
      "\n",
      "WORD LIST AFTER STOP WORDS\n",
      "['n', 'stein', 'education', 'data', 'analytics', 'visualization', 'boot', 'camp', 'graduate', 'experience', 'creating', 'pivot', 'tables', 'vba', 'scripts', 'excel', 'modeling', 'forecasting', 'data', 'basic', 'statistics', 'writing', 'python', 'scripts', 'analyze', 'data', 'sets', 'from', 'files', 'apis', 'social', 'media', 'mining', 'python', 'mysql', 'mongodb', 'databases', 'developing', 'frontend', 'web', 'visualizations', 'html', 'css', 'bootstrap', 'd3', 'leafletjs', 'the', 'tableau', 'business', 'intelligence', 'software', 'performing', 'big', 'data', 'analytics', 'hadoop', 'machine', 'learning', 'algorithms', 'skills', 'microsoft', 'excel', 'python', 'javascript', 'htmlcss', 'api', 'interactions', 'social', 'media', 'mining', 'sql', 'hadoop', 'tableau', 'advanced', 'statistics', 'machine', 'learning', 'r', 'gitgithub', 'interests', 'contributing', 'opensource', 'software', 'data', 'analytics', 'python', 'pandas', 'designing', 'data', 'visualization', 'web', 'apps', 'html', 'css', 'javascript', 'd3', 'big', 'data', 'the', 'cloud', 'aws']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Required Skills Match using Set Intersection\n",
    "print('REQUIRED SKILLS')\n",
    "print(resume & REQUIRED_SKILLS)\n",
    "\n",
    "# Calculate the Desired Skills Match using Set Intersection\n",
    "print('DESIRED SKILLS')\n",
    "print(resume & DESIRED_SKILLS)\n",
    "\n",
    "\n",
    "# Word Punctuation Cleaning\n",
    "word_list = [word for word in word_list if word not in string.punctuation]\n",
    "print('\\nWORD LIST AFTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Character Punctuation Cleaning\n",
    "word_list = [''.join(char for char in word if char not in string.punctuation) for word in word_list]\n",
    "print('\\nWORD LIST AFTER CHARACTER PUNCTUATION REMOVAL')\n",
    "print(word_list)\n",
    "\n",
    "# Clean Stop Words\n",
    "stop_words = [\"and\", \"with\", \"using\", \"##\", \"working\", \"in\", \"to\", \"frank\"]\n",
    "word_list = [word for word in word_list if word not in stop_words]\n",
    "print('\\nWORD LIST AFTER STOP WORDS')\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, word_count dictionary is intialized by defining it in the first line of code. the .fromkeys(word_list, 0) defines where values will be populated from, and what the values will be, word in word_list.\n",
    "\n",
    "The for loop is used to loop through the word_list we defined as the dictionary key, and for every value [word] in word_list that is identified add (+=) 1 to the word_count.\n",
    "\n",
    "Since its a bonus, I'll take a guess at it. Counter is a function that has to be imported through the dependency collections at the beginning of the code. The function essentially negates the need to write out the word_list loop because it is a built in function that keeps track of how many times equivalent values are added. In this case I believe that would be, how many times [word] is found on word_list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Top 10 Words\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# Resume Word Count\n",
    "# ==========================\n",
    "# Initialize a dictionary with default values equal to zero\n",
    "word_count = {}.fromkeys(word_list, 0)\n",
    "\n",
    "# Loop through the word list and count each word.\n",
    "for word in word_list:\n",
    "    word_count[word] += 1\n",
    "# print(word_count)\n",
    "\n",
    "# Bonus using collections.Counter\n",
    "word_counter = Counter(word_list)\n",
    "# print(word_counter)\n",
    "\n",
    "# Comparing both word count solutions\n",
    "print(word_count == word_counter)\n",
    "\n",
    "# Top 10 Words\n",
    "print(\"Top 10 Words\")\n",
    "print(\"=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, first a new list is created called sorted_words. Then the sorted() function is passed on the dictionary word_count, accessing the values from the word_count dictionary (as denoted by .get fucntion), from the end of the list to the beginning (as denoted by reverse=True).\n",
    "\n",
    "The values that are sorted are passed through [:10], which means to return values up to but not including columns 1-10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: data                 Count: 7\n",
      "Token: python               Count: 4\n",
      "Token: analytics            Count: 3\n",
      "Token: visualization        Count: 2\n",
      "Token: scripts              Count: 2\n",
      "Token: excel                Count: 2\n",
      "Token: statistics           Count: 2\n",
      "Token: social               Count: 2\n",
      "Token: media                Count: 2\n",
      "Token: mining               Count: 2\n"
     ]
    }
   ],
   "source": [
    "# Sort words by count and print the top 10\n",
    "sorted_words = []\n",
    "for word in sorted(word_count, key=word_count.get, reverse=True)[0:10]:\n",
    "    print(f\"Token: {word:20} Count: {word_count[word]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
